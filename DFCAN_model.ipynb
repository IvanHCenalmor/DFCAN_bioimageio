{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b72ad292",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bioimageio.core<0.6,>=0.5 in /home/cocomputer/anaconda3/envs/test_dfcan/lib/python3.10/site-packages (0.5.8)\n",
      "Requirement already satisfied: ruamel.yaml in /home/cocomputer/anaconda3/envs/test_dfcan/lib/python3.10/site-packages (from bioimageio.core<0.6,>=0.5) (0.17.21)\n",
      "Requirement already satisfied: bioimageio.spec==0.4.9.* in /home/cocomputer/anaconda3/envs/test_dfcan/lib/python3.10/site-packages (from bioimageio.core<0.6,>=0.5) (0.4.9)\n",
      "Requirement already satisfied: tifffile in /home/cocomputer/anaconda3/envs/test_dfcan/lib/python3.10/site-packages (from bioimageio.core<0.6,>=0.5) (2023.3.21)\n",
      "Requirement already satisfied: imageio>=2.5 in /home/cocomputer/anaconda3/envs/test_dfcan/lib/python3.10/site-packages (from bioimageio.core<0.6,>=0.5) (2.27.0)\n",
      "Requirement already satisfied: tqdm in /home/cocomputer/anaconda3/envs/test_dfcan/lib/python3.10/site-packages (from bioimageio.core<0.6,>=0.5) (4.65.0)\n",
      "Requirement already satisfied: xarray in /home/cocomputer/anaconda3/envs/test_dfcan/lib/python3.10/site-packages (from bioimageio.core<0.6,>=0.5) (2023.3.0)\n",
      "Requirement already satisfied: numpy in /home/cocomputer/anaconda3/envs/test_dfcan/lib/python3.10/site-packages (from bioimageio.core<0.6,>=0.5) (1.23.5)\n",
      "Requirement already satisfied: marshmallow<4.0,>=3.6.0 in /home/cocomputer/anaconda3/envs/test_dfcan/lib/python3.10/site-packages (from bioimageio.spec==0.4.9.*->bioimageio.core<0.6,>=0.5) (3.19.0)\n",
      "Requirement already satisfied: requests in /home/cocomputer/anaconda3/envs/test_dfcan/lib/python3.10/site-packages (from bioimageio.spec==0.4.9.*->bioimageio.core<0.6,>=0.5) (2.28.1)\n",
      "Requirement already satisfied: typing-extensions in /home/cocomputer/anaconda3/envs/test_dfcan/lib/python3.10/site-packages (from bioimageio.spec==0.4.9.*->bioimageio.core<0.6,>=0.5) (4.4.0)\n",
      "Requirement already satisfied: marshmallow-jsonschema in /home/cocomputer/anaconda3/envs/test_dfcan/lib/python3.10/site-packages (from bioimageio.spec==0.4.9.*->bioimageio.core<0.6,>=0.5) (0.13.0)\n",
      "Requirement already satisfied: typer in /home/cocomputer/anaconda3/envs/test_dfcan/lib/python3.10/site-packages (from bioimageio.spec==0.4.9.*->bioimageio.core<0.6,>=0.5) (0.7.0)\n",
      "Requirement already satisfied: marshmallow-union in /home/cocomputer/anaconda3/envs/test_dfcan/lib/python3.10/site-packages (from bioimageio.spec==0.4.9.*->bioimageio.core<0.6,>=0.5) (0.1.15.post1)\n",
      "Requirement already satisfied: packaging>=17.0 in /home/cocomputer/anaconda3/envs/test_dfcan/lib/python3.10/site-packages (from bioimageio.spec==0.4.9.*->bioimageio.core<0.6,>=0.5) (23.0)\n",
      "Requirement already satisfied: pillow>=8.3.2 in /home/cocomputer/anaconda3/envs/test_dfcan/lib/python3.10/site-packages (from imageio>=2.5->bioimageio.core<0.6,>=0.5) (9.4.0)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.6 in /home/cocomputer/anaconda3/envs/test_dfcan/lib/python3.10/site-packages (from ruamel.yaml->bioimageio.core<0.6,>=0.5) (0.2.7)\n",
      "Requirement already satisfied: pandas<2,>=1.4 in /home/cocomputer/anaconda3/envs/test_dfcan/lib/python3.10/site-packages (from xarray->bioimageio.core<0.6,>=0.5) (1.5.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/cocomputer/anaconda3/envs/test_dfcan/lib/python3.10/site-packages (from pandas<2,>=1.4->xarray->bioimageio.core<0.6,>=0.5) (2022.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/cocomputer/anaconda3/envs/test_dfcan/lib/python3.10/site-packages (from pandas<2,>=1.4->xarray->bioimageio.core<0.6,>=0.5) (2.8.2)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/cocomputer/anaconda3/envs/test_dfcan/lib/python3.10/site-packages (from requests->bioimageio.spec==0.4.9.*->bioimageio.core<0.6,>=0.5) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/cocomputer/anaconda3/envs/test_dfcan/lib/python3.10/site-packages (from requests->bioimageio.spec==0.4.9.*->bioimageio.core<0.6,>=0.5) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/cocomputer/anaconda3/envs/test_dfcan/lib/python3.10/site-packages (from requests->bioimageio.spec==0.4.9.*->bioimageio.core<0.6,>=0.5) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/cocomputer/anaconda3/envs/test_dfcan/lib/python3.10/site-packages (from requests->bioimageio.spec==0.4.9.*->bioimageio.core<0.6,>=0.5) (1.26.14)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/cocomputer/anaconda3/envs/test_dfcan/lib/python3.10/site-packages (from typer->bioimageio.spec==0.4.9.*->bioimageio.core<0.6,>=0.5) (8.0.4)\n",
      "Requirement already satisfied: six>=1.5 in /home/cocomputer/anaconda3/envs/test_dfcan/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas<2,>=1.4->xarray->bioimageio.core<0.6,>=0.5) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cocomputer/anaconda3/envs/test_dfcan/lib/python3.10/site-packages/bioimageio/spec/shared/_resolve_source.py:437: CacheWarning: found cached /tmp/cocomputer/bioimageio_cache/https/raw.githubusercontent.com/bioimage-io/bioimage.io/main/site.config.json. Skipping download of https://raw.githubusercontent.com/bioimage-io/bioimage.io/main/site.config.json.\n",
      "  warnings.warn(f\"found cached {local_path}. Skipping download of {uri}.\", category=CacheWarning)\n",
      "/home/cocomputer/anaconda3/envs/test_dfcan/lib/python3.10/site-packages/bioimageio/spec/shared/_resolve_source.py:437: CacheWarning: found cached /tmp/cocomputer/bioimageio_cache/https/bioimage-io.github.io/collection-bioimage-io/collection.json. Skipping download of https://bioimage-io.github.io/collection-bioimage-io/collection.json.\n",
      "  warnings.warn(f\"found cached {local_path}. Skipping download of {uri}.\", category=CacheWarning)\n",
      "2023-03-30 15:34:35.484954: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "!pip install \"bioimageio.core>=0.5,<0.6\" \n",
    "\n",
    "from shutil import rmtree\n",
    "from bioimageio.core.build_spec import build_model, add_weights\n",
    "from bioimageio.core.resource_tests import test_model\n",
    "from bioimageio.core.weight_converter.keras import convert_weights_to_tensorflow_saved_model_bundle\n",
    "from bioimageio.core import load_raw_resource_description, load_resource_description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ecc07c",
   "metadata": {},
   "source": [
    "# Imports of TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aad1bf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, Conv3D\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Input, add, multiply, Lambda\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, Callback, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.image import ssim_multiscale as mssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d6c2797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "print(tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "613b5c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "######\n",
    "\n",
    "## Loss function definition used in the paper from nature methods\n",
    "def loss_dfcan(y_true, y_pred):\n",
    "  mse = tf.keras.losses.MeanSquaredError()\n",
    "  ssim = tf.image.ssim(y_true, y_pred, max_val=1)\n",
    "  res = mse(y_true, y_pred) + 0.1*(1-ssim)\n",
    "  return res\n",
    "\n",
    "######\n",
    "\n",
    "## DFCAN network definition. We follow the code from:\n",
    "### [Chang Qiao](https://github.com/qc17-THU/DL-SR/tree/main/src) (MIT license).\n",
    "#### Common methods for both DFCAN and DFGAN adapted from `common.py`:\n",
    "\n",
    "\n",
    "def gelu(x):\n",
    "    cdf = 0.5 * (1.0 + tf.math.erf(x / tf.sqrt(2.0)))\n",
    "    return x * cdf\n",
    "\n",
    "\n",
    "def fft2d(input, gamma=0.1):\n",
    "    temp = K.permute_dimensions(input, (0, 3, 1, 2))\n",
    "    fft = tf.signal.fft2d(tf.complex(temp, tf.zeros_like(temp)))\n",
    "    absfft = tf.math.pow(tf.math.abs(fft)+1e-8, gamma)\n",
    "    output = K.permute_dimensions(absfft, (0, 2, 3, 1))\n",
    "    return output\n",
    "\n",
    "\n",
    "def fft3d(input, gamma=0.1):\n",
    "    input = apodize3d(input, napodize=5)\n",
    "    temp = K.permute_dimensions(input, (0, 4, 1, 2, 3))\n",
    "    fft = tf.fft3d(tf.complex(temp, tf.zeros_like(temp)))\n",
    "    absfft = tf.math.pow(tf.math.abs(fft) + 1e-8, gamma)\n",
    "    output = K.permute_dimensions(absfft, (0, 2, 3, 4, 1))\n",
    "    return output\n",
    "\n",
    "\n",
    "def fftshift2d(input, size_psc):\n",
    "    bs, h, w, ch = input.get_shape().as_list()\n",
    "    fs11 = input[:, -h // 2:h, -w // 2:w, :]\n",
    "    fs12 = input[:, -h // 2:h, 0:w // 2, :]\n",
    "    fs21 = input[:, 0:h // 2, -w // 2:w, :]\n",
    "    fs22 = input[:, 0:h // 2, 0:w // 2, :]\n",
    "    output = tf.concat([tf.concat([fs11, fs21], axis=1), tf.concat([fs12, fs22], axis=1)], axis=2)\n",
    "    output = tf.image.resize(output, (size_psc, size_psc))\n",
    "    return output\n",
    "\n",
    "\n",
    "def fftshift3d(input, size_psc=64):\n",
    "    bs, h, w, z, ch = input.get_shape().as_list()\n",
    "    fs111 = input[:, -h // 2:h, -w // 2:w, -z // 2 + 1:z, :]\n",
    "    fs121 = input[:, -h // 2:h, 0:w // 2, -z // 2 + 1:z, :]\n",
    "    fs211 = input[:, 0:h // 2, -w // 2:w, -z // 2 + 1:z, :]\n",
    "    fs221 = input[:, 0:h // 2, 0:w // 2, -z // 2 + 1:z, :]\n",
    "    fs112 = input[:, -h // 2:h, -w // 2:w, 0:z // 2 + 1, :]\n",
    "    fs122 = input[:, -h // 2:h, 0:w // 2, 0:z // 2 + 1, :]\n",
    "    fs212 = input[:, 0:h // 2, -w // 2:w, 0:z // 2 + 1, :]\n",
    "    fs222 = input[:, 0:h // 2, 0:w // 2, 0:z // 2 + 1, :]\n",
    "    output1 = tf.concat([tf.concat([fs111, fs211], axis=1), tf.concat([fs121, fs221], axis=1)], axis=2)\n",
    "    output2 = tf.concat([tf.concat([fs112, fs212], axis=1), tf.concat([fs122, fs222], axis=1)], axis=2)\n",
    "    output0 = tf.concat([output1, output2], axis=3)\n",
    "    output = []\n",
    "    for iz in range(z):\n",
    "        output.append(tf.image.resize(output0[:, :, :, iz, :], (size_psc, size_psc)))\n",
    "    output = tf.stack(output, axis=3)\n",
    "    return output\n",
    "\n",
    "\n",
    "def apodize2d(img, napodize=10):\n",
    "    bs, ny, nx, ch = img.get_shape().as_list()\n",
    "    img_apo = img[:, napodize:ny-napodize, :, :]\n",
    "\n",
    "    imageUp = img[:, 0:napodize, :, :]\n",
    "    imageDown = img[:, ny-napodize:, :, :]\n",
    "    diff = (imageDown[:, -1::-1, :, :] - imageUp) / 2\n",
    "    l = np.arange(napodize)\n",
    "    fact_raw = 1 - np.sin((l + 0.5) / napodize * np.pi / 2)\n",
    "    fact = fact_raw[np.newaxis, :, np.newaxis, np.newaxis]\n",
    "    fact = tf.convert_to_tensor(fact, dtype=tf.float32)\n",
    "    fact = tf.tile(fact, [tf.shape(img)[0], 1, nx, ch])\n",
    "    factor = diff * fact\n",
    "    imageUp = tf.add(imageUp, factor)\n",
    "    imageDown = tf.subtract(imageDown, factor[:, -1::-1, :, :])\n",
    "    img_apo = tf.concat([imageUp, img_apo, imageDown], axis=1)\n",
    "\n",
    "    imageLeft = img_apo[:, :, 0:napodize, :]\n",
    "    imageRight = img_apo[:, :, nx-napodize:, :]\n",
    "    img_apo = img_apo[:, :, napodize:nx-napodize, :]\n",
    "    diff = (imageRight[:, :, -1::-1, :] - imageLeft) / 2\n",
    "    fact = fact_raw[np.newaxis, np.newaxis, :, np.newaxis]\n",
    "    fact = tf.convert_to_tensor(fact, dtype=tf.float32)\n",
    "    fact = tf.tile(fact, [tf.shape(img)[0], ny, 1, ch])\n",
    "    factor = diff * fact\n",
    "    imageLeft = tf.add(imageLeft, factor)\n",
    "    imageRight = tf.subtract(imageRight, factor[:, :, -1::-1, :])\n",
    "    img_apo = tf.concat([imageLeft, img_apo, imageRight], axis=2)\n",
    "\n",
    "    return img_apo\n",
    "\n",
    "\n",
    "def apodize3d(img, napodize=5):\n",
    "    bs, ny, nx, nz, ch = img.get_shape().as_list()\n",
    "    img_apo = img[:, napodize:ny-napodize, :, :, :]\n",
    "\n",
    "    imageUp = img[:, 0:napodize, :, :, :]\n",
    "    imageDown = img[:, ny-napodize:, :, :, :]\n",
    "    diff = (imageDown[:, -1::-1, :, :, :] - imageUp) / 2\n",
    "    l = np.arange(napodize)\n",
    "    fact_raw = 1 - np.sin((l + 0.5) / napodize * np.pi / 2)\n",
    "    fact = fact_raw[np.newaxis, :, np.newaxis, np.newaxis, np.newaxis]\n",
    "    fact = tf.convert_to_tensor(fact, dtype=tf.float32)\n",
    "    fact = tf.tile(fact, [tf.shape(img)[0], 1, nx, nz, ch])\n",
    "    factor = diff * fact\n",
    "    imageUp = tf.add(imageUp, factor)\n",
    "    imageDown = tf.subtract(imageDown, factor[:, -1::-1, :, :, :])\n",
    "    img_apo = tf.concat([imageUp, img_apo, imageDown], axis=1)\n",
    "\n",
    "    imageLeft = img_apo[:, :, 0:napodize, :, :]\n",
    "    imageRight = img_apo[:, :, nx-napodize:, :, :]\n",
    "    img_apo = img_apo[:, :, napodize:nx-napodize, :, :]\n",
    "    diff = (imageRight[:, :, -1::-1, :, :] - imageLeft) / 2\n",
    "    fact = fact_raw[np.newaxis, np.newaxis, :, np.newaxis, np.newaxis]\n",
    "    fact = tf.convert_to_tensor(fact, dtype=tf.float32)\n",
    "    fact = tf.tile(fact, [tf.shape(img)[0], ny, 1, nz, ch])\n",
    "    factor = diff * fact\n",
    "    imageLeft = tf.add(imageLeft, factor)\n",
    "    imageRight = tf.subtract(imageRight, factor[:, :, -1::-1, :, :])\n",
    "    img_apo = tf.concat([imageLeft, img_apo, imageRight], axis=2)\n",
    "\n",
    "    return img_apo\n",
    "\n",
    "\n",
    "def pixel_shiffle(layer_in, scale):\n",
    "    return tf.nn.depth_to_space(layer_in, block_size=scale)\n",
    "\n",
    "\n",
    "def global_average_pooling2d(layer_in):\n",
    "    return tf.reduce_mean(layer_in, axis=(1, 2), keepdims=True)\n",
    "\n",
    "\n",
    "def global_average_pooling3d(layer_in):\n",
    "    return tf.reduce_mean(layer_in, axis=(1, 2, 3), keepdims=True)\n",
    "\n",
    "\n",
    "def conv_block2d(input, channel_size):\n",
    "    conv = Conv2D(channel_size[0], kernel_size=3, padding='same')(input)\n",
    "    conv = LeakyReLU(alpha=0.1)(conv)\n",
    "    conv = Conv2D(channel_size[1], kernel_size=3, padding='same')(conv)\n",
    "    conv = LeakyReLU(alpha=0.1)(conv)\n",
    "    return conv\n",
    "\n",
    "\n",
    "def conv_block3d(input, channel_size):\n",
    "    conv = Conv3D(channel_size[0], kernel_size=3, padding='same')(input)\n",
    "    conv = LeakyReLU(alpha=0.1)(conv)\n",
    "    conv = Conv3D(channel_size[1], kernel_size=3, padding='same')(conv)\n",
    "    conv = LeakyReLU(alpha=0.1)(conv)\n",
    "    return conv\n",
    "\n",
    "\n",
    "## DFCAN specific methods:\n",
    "\n",
    "def FCALayer(input, channel, size_psc, reduction=16):\n",
    "    absfft1 = Lambda(fft2d, arguments={'gamma': 0.8})(input)\n",
    "    absfft1 = Lambda(fftshift2d, arguments={'size_psc': size_psc})(absfft1)\n",
    "    absfft2 = Conv2D(channel, kernel_size=3, activation='relu', padding='same')(absfft1)\n",
    "    W = Lambda(global_average_pooling2d)(absfft2)\n",
    "    W = Conv2D(channel // reduction, kernel_size=1, activation='relu', padding='same')(W)\n",
    "    W = Conv2D(channel, kernel_size=1, activation='sigmoid', padding='same')(W)\n",
    "    mul = multiply([input, W])\n",
    "    return mul\n",
    "\n",
    "\n",
    "def FCAB(input, channel, size_psc):\n",
    "    conv = Conv2D(channel, kernel_size=3, padding='same')(input)\n",
    "    conv = Lambda(gelu)(conv)\n",
    "    conv = Conv2D(channel, kernel_size=3, padding='same')(conv)\n",
    "    conv = Lambda(gelu)(conv)\n",
    "    att = FCALayer(conv, channel, size_psc=size_psc, reduction=16)\n",
    "    output = add([att, input])\n",
    "    return output\n",
    "\n",
    "\n",
    "def ResidualGroup(input, channel, size_psc, n_RCAB = 4):\n",
    "    conv = input\n",
    "    for _ in range(n_RCAB):\n",
    "        conv = FCAB(conv, channel=channel, size_psc=size_psc)\n",
    "    conv = add([conv, input])\n",
    "    return conv\n",
    "\n",
    "\n",
    "def DFCAN(input_shape, scale=4, n_ResGroup = 4, n_RCAB = 4, pretrained_weights=None):\n",
    "    inputs = Input(input_shape)\n",
    "    size_psc = input_shape[0]\n",
    "    conv = Conv2D(64, kernel_size=3, padding='same')(inputs)\n",
    "    conv = Lambda(gelu)(conv)\n",
    "    for _ in range(n_ResGroup):\n",
    "        conv = ResidualGroup(conv, 64, size_psc, n_RCAB = 4)\n",
    "    conv = Conv2D(64 * (scale ** 2), kernel_size=3, padding='same')(conv)\n",
    "    conv = Lambda(gelu)(conv)\n",
    "    if scale > 1:\n",
    "      conv = Lambda(pixel_shiffle, arguments={'scale': scale})(conv)\n",
    "    conv = Conv2D(1, kernel_size=3, padding='same')(conv)\n",
    "    output = Activation('sigmoid')(conv)\n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28173ac",
   "metadata": {},
   "source": [
    "# Test if creating the model works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe6b05cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-30 15:34:38.475577: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-30 15:34:38.477717: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "dfcan_model = DFCAN((128,128,1), scale=4, n_ResGroup = 4, n_RCAB = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2479d1",
   "metadata": {},
   "source": [
    "# Export the model in BioimageIO format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e8e6a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-image in /home/cocomputer/anaconda3/envs/test_dfcan/lib/python3.10/site-packages (0.20.0)\n",
      "Requirement already satisfied: numpy>=1.21.1 in /home/cocomputer/anaconda3/envs/test_dfcan/lib/python3.10/site-packages (from scikit-image) (1.23.5)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /home/cocomputer/anaconda3/envs/test_dfcan/lib/python3.10/site-packages (from scikit-image) (2023.3.21)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/cocomputer/anaconda3/envs/test_dfcan/lib/python3.10/site-packages (from scikit-image) (23.0)\n",
      "Requirement already satisfied: networkx>=2.8 in /home/cocomputer/anaconda3/envs/test_dfcan/lib/python3.10/site-packages (from scikit-image) (3.0)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in /home/cocomputer/anaconda3/envs/test_dfcan/lib/python3.10/site-packages (from scikit-image) (0.2)\n",
      "Requirement already satisfied: scipy>=1.8 in /home/cocomputer/anaconda3/envs/test_dfcan/lib/python3.10/site-packages (from scikit-image) (1.10.0)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /home/cocomputer/anaconda3/envs/test_dfcan/lib/python3.10/site-packages (from scikit-image) (1.4.1)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /home/cocomputer/anaconda3/envs/test_dfcan/lib/python3.10/site-packages (from scikit-image) (2.27.0)\n",
      "Requirement already satisfied: pillow>=9.0.1 in /home/cocomputer/anaconda3/envs/test_dfcan/lib/python3.10/site-packages (from scikit-image) (9.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "582e3598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 4s 4s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cocomputer/anaconda3/envs/test_dfcan/lib/python3.10/site-packages/bioimageio/spec/shared/schema.py:46: ValidationWarning: tags: Missing tags corresponding to bioimage.io categories: [{'modality': ['electron-microscopy', 'cryo-electron-microscopy', 'fluorescence-light-microscopy', 'transmission-light-microscopy', 'super-resolution-microscopy', 'x-ray-microscopy', 'force-microscopy', 'high-content-imaging', 'whole-slide-imaging', 'other']}, {'dims': ['2d', '3d', '2d-t', '3d-t']}, {'content': ['cells', 'nuclei', 'extracellular-vesicles', 'tissue', 'plant', 'mitochondria', 'vasculature', 'cell-membrane', 'brain', 'whole-organism']}, {'framework': ['tensorflow', 'pytorch', 'tensorflow.js']}, {'network': ['unet', 'densenet', 'resnet', 'inception', 'shufflenet']}, {'task': ['semantic-segmentation', 'instance-segmentation', 'object-detection', 'image-classification', 'denoising', 'image-restoration', 'image-reconstruction', 'in-silico-labeling']}]\n",
      "  warnings.warn(msg, category=ValidationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 83). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf_weights/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf_weights/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow model exported to tf_weights.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cocomputer/anaconda3/envs/test_dfcan/lib/python3.10/site-packages/bioimageio/spec/shared/schema.py:46: ValidationWarning: tags: Missing tags corresponding to bioimage.io categories: [{'modality': ['electron-microscopy', 'cryo-electron-microscopy', 'fluorescence-light-microscopy', 'transmission-light-microscopy', 'super-resolution-microscopy', 'x-ray-microscopy', 'force-microscopy', 'high-content-imaging', 'whole-slide-imaging', 'other']}, {'dims': ['2d', '3d', '2d-t', '3d-t']}, {'content': ['cells', 'nuclei', 'extracellular-vesicles', 'tissue', 'plant', 'mitochondria', 'vasculature', 'cell-membrane', 'brain', 'whole-organism']}, {'framework': ['tensorflow', 'pytorch', 'tensorflow.js']}, {'network': ['unet', 'densenet', 'resnet', 'inception', 'shufflenet']}, {'task': ['semantic-segmentation', 'instance-segmentation', 'object-detection', 'image-classification', 'denoising', 'image-restoration', 'image-reconstruction', 'in-silico-labeling']}]\n",
      "  warnings.warn(msg, category=ValidationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "The bioimage.io model was successfully exported to ./DFCAN_test.bioimage.io.model/DFCAN_test.zip\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "# ------------- User input ------------\n",
    "# information about the model\n",
    "#@markdown ##Introduce the metadata of the model architecture:\n",
    "Trained_model_name    = \"DFCAN_test\" #@param {type:\"string\"}\n",
    "Trained_model_authors =  \"[Author Name and Surname 1,  Author Name and Surname 2]\" #@param {type:\"string\"}\n",
    "Trained_model_authors_affiliation =  \"[Affiliation 1, Affiliation 2]\" #@param {type:\"string\"}\n",
    "Trained_model_description = \"DFCAN\" #@param {type:\"string\"}\n",
    "Trained_model_license = 'MIT'#@param {type:\"string\"}\n",
    "Trained_model_references = [] \n",
    "Trained_model_DOI = [] \n",
    "\n",
    "\n",
    "# Training data\n",
    "# ---------------------------------------\n",
    "#@markdown ##Include information about training data (optional):\n",
    "include_training_data = False #@param {type: \"boolean\"}\n",
    "#@markdown ### - If it is published in the BioImage Model Zoo, please, provide the ID\n",
    "data_from_bioimage_model_zoo = False #@param {type: \"boolean\"}\n",
    "training_data_ID = ''#@param {type:\"string\"}\n",
    "#@markdown ### - If not, please provide the URL tot he data and a short description\n",
    "training_data_source = ''#@param {type:\"string\"}\n",
    "training_data_description = ''#@param {type:\"string\"}\n",
    "\n",
    "#@markdown ##Introduce the pixel size (in microns) of the image provided as an example of the model processing:\n",
    "# information about the example image\n",
    "PixelSize = 0.0004 #@param {type:\"number\"}\n",
    "\n",
    "default_example_image = False #@param {type:\"boolean\"}\n",
    "#@markdown ###If not, please input:\n",
    "fileID = \"./0000.tif\" #@param {type:\"string\"}\n",
    "\n",
    "\n",
    "if default_example_image:\n",
    "    source_dir_list = os.listdir(Source_QC_folder)\n",
    "    fileID = os.path.join(Source_QC_folder, source_dir_list[0])\n",
    "\n",
    "# create the author spec input\n",
    "auth_names = Trained_model_authors[1:-1].split(\",\")\n",
    "auth_affs = Trained_model_authors_affiliation[1:-1].split(\",\")\n",
    "assert len(auth_names) == len(auth_affs)\n",
    "authors = [{\"name\": auth_name, \"affiliation\": auth_aff} for auth_name, auth_aff in zip(auth_names, auth_affs)]\n",
    "\n",
    "# I would recommend using CC-BY-4 as licencese\n",
    "license = Trained_model_license\n",
    "\n",
    "# where to save the model\n",
    "full_QC_model_path = '.'\n",
    "output_root = os.path.join(full_QC_model_path, Trained_model_name + '.bioimage.io.model')\n",
    "os.makedirs(output_root, exist_ok=True)\n",
    "output_path = os.path.join(output_root, f\"{Trained_model_name}.zip\")\n",
    "\n",
    "# create a markdown readme with information\n",
    "readme_path = os.path.join(output_root, \"README.md\")\n",
    "with open(readme_path, \"w\") as f:\n",
    "  f.write(\"Visit https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki\")\n",
    "\n",
    "# create the citation input spec\n",
    "assert len(Trained_model_DOI) == len(Trained_model_references)\n",
    "citations = [{'text': text, 'doi': doi} for text, doi in zip(Trained_model_references, Trained_model_DOI)]\n",
    "\n",
    "# create the training data\n",
    "if include_training_data:\n",
    "    if data_from_bioimage_model_zoo:\n",
    "      training_data = {\"id\": training_data_ID}\n",
    "    else:\n",
    "      training_data = {\"source\": training_data_source,\n",
    "                       \"description\": training_data_description}\n",
    "else:\n",
    "    training_data={}\n",
    "\n",
    "\n",
    "test_img = io.imread(fileID)\n",
    "test_img = test_img[None, ..., None] \n",
    "    \n",
    "# load the model\n",
    "compiled_weight_path = os.path.join('.', 'weights_best.h5')\n",
    "dfcan_model = DFCAN(test_img[0].shape, scale=4, n_ResGroup = 4, n_RCAB = 4)\n",
    "dfcan_model.load_weights(compiled_weight_path)\n",
    "weight_path = os.path.join('.', 'keras_weights.hdf5')\n",
    "dfcan_model.save(weight_path)\n",
    "\n",
    "# load the input image, crop it if necessary and save as numpy file\n",
    "# Save the test image\n",
    "test_in_path = os.path.join(output_root, \"test_input.npy\")\n",
    "np.save(test_in_path, test_img)  # add batch and channel axis\n",
    "\n",
    "test_prediction = dfcan_model.predict(test_img)\n",
    "test_out_path = os.path.join(output_root, \"test_output.npy\")\n",
    "np.save(test_out_path, test_prediction)\n",
    "\n",
    "# attach the QC report to the model (if it exists)\n",
    "qc_path = os.path.join(full_QC_model_path, 'Quality Control', 'training_evaluation.csv')\n",
    "if os.path.exists(qc_path):\n",
    "  attachments = {\"files\": [qc_path]}\n",
    "else:\n",
    "  attachments = None\n",
    "\n",
    "\n",
    "min_percentile = 0\n",
    "max_percentile = 100\n",
    "pixel_size = {\"x\": PixelSize, \"y\": PixelSize}\n",
    "\n",
    "input_name = dfcan_model.input.name\n",
    "output_name = dfcan_model.output.name.split('/')[0] # Because has an activation and changes its name\n",
    "\n",
    "kwargs = dict(\n",
    "  input_names=[input_name],\n",
    "  input_axes=[\"bxyc\"],\n",
    "  pixel_sizes=[pixel_size],\n",
    "  preprocessing=None\n",
    ")\n",
    "\n",
    "output_spec = dict(\n",
    "  output_names=[output_name],\n",
    "  output_axes=[\"bxyc\"],\n",
    "  postprocessing=None\n",
    ")\n",
    "kwargs.update(output_spec)\n",
    "\n",
    "# export the model with keras weihgts\n",
    "build_model(\n",
    "    weight_uri=weight_path,\n",
    "    test_inputs=[test_in_path],\n",
    "    test_outputs=[test_out_path],\n",
    "    name=Trained_model_name,\n",
    "    description=Trained_model_description,\n",
    "    authors=authors,\n",
    "    attachments=attachments,\n",
    "    tags=['zerocostdl4mic', 'deepimagej', 'super-resolution', 'dfcan'],\n",
    "    license=license,\n",
    "    documentation=readme_path,\n",
    "    cite=citations,\n",
    "    output_path=output_path,\n",
    "    tensorflow_version=tf.__version__,\n",
    "    training_data = training_data,\n",
    "    add_deepimagej_config=True,\n",
    "    **kwargs\n",
    ")\n",
    "\n",
    "QC_model_folder = \".\"\n",
    "\n",
    "# convert the keras weights to tensorflow and add them to the model\n",
    "tf_weight_path = os.path.join(QC_model_folder, \"tf_weights\")\n",
    "# we need to make sure that the tf weight folder does not exist\n",
    "if os.path.exists(tf_weight_path):\n",
    "  rmtree(tf_weight_path)\n",
    "convert_weights_to_tensorflow_saved_model_bundle(output_path, tf_weight_path + \".zip\")\n",
    "add_weights(output_path, tf_weight_path + \".zip\", output_path, tensorflow_version=tf.__version__)\n",
    "\n",
    "# check that the model works for keras and tensorflow \n",
    "res = test_model(output_path, weight_format=\"keras_hdf5\")\n",
    "success = True\n",
    "if res[-1][\"error\"] is not None:\n",
    "  success = False\n",
    "  print(\"test-model failed for keras weights:\", res[-1][\"error\"])\n",
    "  \n",
    "res = test_model(output_path, weight_format=\"tensorflow_saved_model_bundle\")\n",
    "if res[-1][\"error\"] is not None:\n",
    "  success = False\n",
    "  print(\"test-model failed for tensorflow weights:\", res[-1][\"error\"])\n",
    "\n",
    "if success:\n",
    "  print(\"The bioimage.io model was successfully exported to\", output_path)\n",
    "else:\n",
    "  print(\"The bioimage.io model was exported to\", output_path)\n",
    "  print(\"Some tests of the model did not work! You can still download and test the model.\")\n",
    "  print(\"You can still download and test the model, but it may not work as expected.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cdcd2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
